<!DOCTYPE html>
<html>
<head>
    <title>Nathaniel Zuk</title>
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <link rel="stylesheet" type="text/css" href="main_style.css">
    <link href="https://fonts.googleapis.com/css?family=Asap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-112588728-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-112588728-1');
    </script>

    </head>

<body>
    <div class="header">Nathaniel J Zuk</div>
	<div class="menu">
		<a href="index.html"> Home </a>
		<a href="cv.html"> CV </a>
		<a href="projects.html"> Projects </a>
		<a href="music.html"> Music </a>
	</div>
	<div class="main">
    <div class="item" style="justify-content:space-around">
			<img src="NZpic_2020.png" width="250px" alt="Awesome picture of nate">
    </div>
		<div class="item" style="justify-content:space-around">
			<paragraph>
        <p>I am an ELSC-SWC postdoctoral fellow at Hebrew University in Jerusalem, where I am affiliated with <a href="https://elsc.huji.ac.il/faculty-staff/merav-ahissar">Merav Ahissar's lab for Human Perceptual and Cognitive Learning</a> and collaborating with <a href="https://www.lim.bio/">Athena Akrami's Learning, Inference, & Memory Lab</a> at UCL.  Previously, I was a postdoctoral researcher in the <a href="https://www.urmc.rochester.edu/labs/lalor.aspx">Lalor Lab for Computational Cognitive Neurophysiology</a>.</p>

        <p>I use electroencephalography (EEG) to study how the brain parses sound sequences and music in time.  My focus has been on using novel analytical techniques to quantify the neural encoding of acoustic features and cognitive effects when people listen to continuous naturalistic sounds.  Recently, I have been interested in the following questions: How does the brain form expectations in patterned sounds, like those that are found in music? How do we determine where beats are in a piece of music? Are there differences in the timing of neural activity when we listen to different natural sounds? EEG provides temporal acuity sufficient to address these questions. By using machine learning techniques, we can identify the neural processes involved when people listen to audiobooks, music, or other natural sounds.</p>

        <p>I received a PhD from the <a href="http://dms.hms.harvard.edu/shbt/">Harvard Program in Speech and Hearing Bioscience and Technology</a> through the <a href="https://hst.mit.edu/">Harvard-MIT Program in Health Sciences and Technology</a>. I did my doctoral work in <a href="https://research.meei.harvard.edu/neuralcoding/index.html">the EPL Neural Coding Group</a> with Bertrand Delgutte at the Massachusetts Eye and Ear Infirmary, where I studied how the inferior colliculus in the midbrain encodes time-varying interaural time differences (ITD), one of the cues we use to localize sounds.</p>

        <p>I also enjoy writing and arranging music.  Some of my earlier compositions as an undergraduate at the University of Rochester and as a graduate student at MIT are listed in the Music page.</p>

        <p>You can contact me at <span class="impact">nathaniel (dot) zuk (at) mail.huji.ac.il</span></p>
      </paragraph>
		</div>
	</div>
</body>

</html>
